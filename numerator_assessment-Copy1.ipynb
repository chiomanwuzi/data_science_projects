{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de960e86-f7bc-4dcc-93ae-69801eefc66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "7db86f71-363f-46d9-b550-d9ca4fad00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    " # import data sets\n",
    "\n",
    "soda_data =  pd.read_csv(str(os.getcwd()) + \"/soft_drink_sales.csv\")\n",
    "#lower the case of the columns \n",
    "soda_data.columns = soda_data.columns.str.lower()\n",
    "\n",
    "benchmark_data = pd.read_csv(str(os.getcwd()) + \"/benchmarks.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "ca020849-af56-49e8-ba99-d126100c648b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   yearmon    12 non-null     object \n",
      " 1   benchmark  12 non-null     float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 324.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "yearmon      0\n",
       "benchmark    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no missing values\n",
    "\n",
    "benchmark_data.info()\n",
    "benchmark_data.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "fcb5b8af-d9d7-4962-abff-4cd0b97c6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#normalize the data columns between the tables\n",
    "soda_data['yearmon'] = '20' + soda_data['transaction_date'].str.split('/').str[-1] +'-' + soda_data['transaction_date'].str.split('/').str[0]\n",
    "soda_data['yearmon'] = soda_data['yearmon'].apply(lambda x: str(x) if len(str(x)) == 7 else str(x)[:5] + '0' + str(x)[5:])\n",
    "soda_data[['year', 'month']] = soda_data['yearmon'].str.split('-', expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "acb1775e-9b94-4601-a99f-808731eb9ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29798 entries, 0 to 29797\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   user_id             29798 non-null  int64  \n",
      " 1   demographic_weight  29798 non-null  float64\n",
      " 2   basket_id           29798 non-null  int64  \n",
      " 3   channel             29798 non-null  object \n",
      " 4   total_spent         29768 non-null  float64\n",
      " 5   total_units         29798 non-null  int64  \n",
      " 6   trips               29798 non-null  int64  \n",
      " 7   transaction_date    29798 non-null  object \n",
      " 8   yearmon             29798 non-null  object \n",
      " 9   year                29798 non-null  object \n",
      " 10  month               29798 non-null  object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 2.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user_id                0\n",
       "demographic_weight     0\n",
       "basket_id              0\n",
       "channel                0\n",
       "total_spent           30\n",
       "total_units            0\n",
       "trips                  0\n",
       "transaction_date       0\n",
       "yearmon                0\n",
       "year                   0\n",
       "month                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index user_id, check for missing values\n",
    "\n",
    "soda_data.set_index('user_id')\n",
    "soda_data.info()\n",
    "soda_data.isnull().sum() \n",
    "# 30 missing values for total spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae9ac7-ebc5-404d-91cf-b4e24736b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation of missing values\n",
    "\n",
    "impute_method = IterativeImputer(max_iter = 5, random_state = 127)\n",
    "imputed_values = impute_method.fit_transform(soda_data.iloc[:,~soda_data.columns.isin(['user_id','basket_id', 'channel', 'transaction_date', 'yearmon'])])\n",
    "imputed_df = pd.DataFrame(imputed_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb9271-3dcb-4b31-97cc-20d68ce078f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#readjust the names of the imputed columns\n",
    "\n",
    "imputed_df.columns = [\"demographic_weight\",\"total_spent\", \"total_units\",\"trips\"\t,\"year\",\"month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdf032b-f055-44f1-8511-c16d0920b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the imputed df with original df\n",
    "\n",
    "soda_final = soda_data.merge(imputed_df, left_index = True, right_index = True)\n",
    "soda_final = soda_final.iloc[:, ~soda_final.columns.isin(['demographic_weight_x','total_spent_x', 'total_units_x', 'trips_x','year_x', 'month_x' ])]\n",
    "soda_final.columns = ['user_id', 'basket_id', 'channel', 'transaction_date', 'yearmon','demographic_weight', 'total_spent', 'total_units', 'trips','year', 'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3a45f-3350-4672-965c-b0ce4024c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a aggregate table for the sum of the table spent of the ledgar, and the proportion of the total spend compated to the\n",
    "#benchmark grouped monthly\n",
    "\n",
    "sum_sales = soda_final.groupby(['yearmon'])['total_spent'].sum().sort_values() \n",
    "sum_sales = pd.DataFrame(sum_sales)\n",
    "\n",
    "sum_sales = sum_sales.merge(benchmark_data, on = \"yearmon\").sort_values(by = \"yearmon\")\n",
    "sum_sales['coverage_rate'] = sum_sales['total_spent']/sum_sales['benchmark'] * 100\n",
    "sum_sales.columns = [\"yearmon\",\"agg_total_spent\",\"benchmark\",\"coverage_rate\"]\n",
    "sum_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3238764-7bf9-4f61-8469-293ac9496741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create additional variables describing the portionof total sales attributed to each user and the estimate of the \n",
    "#proportion of the benchmark\n",
    "\n",
    "full_data = soda_final.merge(sum_sales, on = \"yearmon\")\n",
    "full_data['sales_proportion'] = full_data['total_spent']/full_data['agg_total_spent']\n",
    "full_data['bench_estimate'] = full_data['sales_proportion'] * full_data['benchmark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea3afba-8806-4ac9-bba4-22dba6e1be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#create alias for transformations of the data used for modeling\n",
    "model_data = full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555aec8a-ad15-46f3-9bd4-558d979b9df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset out variables excluded from modeling or modeling transformations\n",
    "\n",
    "model_data = model_data.iloc[:, ~model_data.columns.isin([\"user_id\", \"basket_id\", \"channel\", \"transaction_date\", \"benchmark\", \"coverage_rate\", \"agg_total_spent\", \"sales_proportion\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab53402-a07b-426d-8990-06bd67c30712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#transform date metrics into strings to furhter convert into ordinal variables\n",
    "\n",
    "model_data['year'] = model_data['year'].apply(str)\n",
    "model_data['month'] = model_data['month'].apply(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e50bf-c9b0-4e21-9a33-2f4a0b333c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert year and month variables into ordinal variables\n",
    "\n",
    "ordinal_encoder_year = OrdinalEncoder(categories = [[\"2020.0\", \"2021.0\"]])\n",
    "ordinal_encoder_month = OrdinalEncoder(categories = [[ '1.0','2.0', '3.0', '4.0','5.0', '6.0','7.0','8.0', '9.0', '10.0','11.0','12.0']])\n",
    "\n",
    "model_data['year'] = ordinal_encoder_year.fit_transform(model_data['year'].values.reshape(-1,1))\n",
    "model_data['month'] = ordinal_encoder_month.fit_transform(model_data['month'].values.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb7faad-c5c9-45ac-bf8a-5a9023f98181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate response and features into separate dataframes\n",
    "\n",
    "feature_set = model_data.iloc[:,:-1]\n",
    "response_var = model_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed3342c-4886-487e-9c76-1d473d002f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a manual training and test set based time based separations, to set up for future forecasting\n",
    "\n",
    "x_train = model_data.iloc[:,:-1][model_data[\"yearmon\"] < \"2021-03\"]\n",
    "y_train = model_data.iloc[:,-1][model_data[\"yearmon\"] < \"2021-03\"]\n",
    "x_test = model_data.iloc[:,:-1][model_data[\"yearmon\"] >= \"2021-03\"]\n",
    "y_test = model_data.iloc[:,-1][model_data[\"yearmon\"] >= \"2021-03\"]\n",
    "\n",
    "x_train = x_train.iloc[:,1:]\n",
    "x_test = x_test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298788f1-1e49-4946-9c51-fc9e20acd2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a small grid search function to find the most optimal hyperparameters for the gradient boosting model\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "def grid_search_models(x_train_df, y_train_df, num_estimators_per_param, random_state): \n",
    "        grid = {'n_estimators': [n for n in range(500,3000,500)[0: num_estimators_per_param]],\n",
    "              'min_child_weight': [n for n in range(1,20,1)[0: num_estimators_per_param]],\n",
    "              'max_depth': [n for n in range(1,10,1)[0: num_estimators_per_param]]}\n",
    "        xgb_grid_search = GridSearchCV(XGBRegressor(random_state = random_state), param_grid = grid,\n",
    "                          cv = KFold(n_splits = 5, shuffle = True, random_state = random_state), scoring = 'f1')\n",
    "        xgb_grid_search.fit(x_train_df, y_train_df)\n",
    "        return(xgb_grid_search.best_params_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee505c7e-4e51-4198-93b9-269d73d3d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the model using the parameters determined by the hyperparameter tuning function\n",
    "\n",
    "xgb_params = grid_search_models(x_train, y_train, 3, 10)\n",
    "\n",
    "regressor = XGBRegressor(n_estimators = xgb_params['n_estimators'], min_child_weight = xgb_params['min_child_weight'], max_depth = xgb_params['max_depth'], booster = \"gbtree\")\n",
    "regressor.fit(x_train, y_train)\n",
    "predictions = pd.DataFrame(regressor.predict(x_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8824a66-f023-4bd9-a5e3-a081b369b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column for the prediction\n",
    "predictions.columns = [\"benchmark_prediction\"]\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24290b7-0a30-4301-b69c-2f8c8846a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index to be able to merge the testing data with the original dataset\n",
    "x_test = x_test.reset_index()\n",
    "x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a7940-f53a-49cf-b56e-3d7fca17d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the results of the predictions with the full testing dataset\n",
    "pred_merge = x_test.merge(predictions, left_index = True, right_index = True)\n",
    "pred_merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55baa1a-6794-4a2f-9967-c51194b633ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the predictions df with the original variables from the sales and benchmark dataframes\n",
    "pred_merge = pred_merge.merge(full_data.iloc[:, full_data.columns.isin(['yearmon', 'benchmark', 'sales_proportion', 'coverage_rate'])], left_on = \"index\", right_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac63b30-f2df-4656-a9d0-0a3da67a2b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize the benchmark data for forecasting and answering the follow up questions\n",
    "\n",
    "benchmark_pred_df = pd.DataFrame(pred_merge.groupby(['yearmon'])['benchmark_prediction'].sum().sort_values())\n",
    "benchmark_pred_df = benchmark_pred_df.merge(benchmark_data, left_index = True, right_on = \"yearmon\")\n",
    "benchmark_pred_df['yearmon'] = pd.to_datetime(benchmark_pred_df['yearmon'])\n",
    "benchmark_pred_df = benchmark_pred_df.set_index('yearmon')\n",
    "benchmark_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ca2bb-3b56-47d6-9b96-d4cc8dff1ee5",
   "metadata": {},
   "source": [
    "2. What is the projected total$sales for the given year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8475d2db-de3e-4e72-8c54-b22b3f922e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages to train a time series and forecast yearly sales\n",
    "\n",
    "from math import sqrt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import acf,pacf\n",
    "from statsmodels.tsa.arima_model import  ARIMA\n",
    "from sklearn import model_selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3add5db-e945-4846-8dd5-37367446c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the timeseries using standard orders and seasonality\n",
    "# fit the model to the testing data results of the boosting model\n",
    "\n",
    "ts_model = sm.tsa.statespace.SARIMAX(benchmark_pred_df['benchmark_prediction'],\n",
    "                                order=(1, 1, 1),\n",
    "                                seasonal_order=(0, 1, 1, 2),\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=True)\n",
    "ts_fit = ts_model.fit()\n",
    "predictions = ts_fit.get_prediction(start=pd.to_datetime('2021-03-01'), dynamic = True)\n",
    "print(ts_fit.summary().tables[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235df5a2-27c9-41b9-ae83-96b6bafc0f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce the confidence intervals for the timeseries\n",
    "\n",
    "prediction_ci = predictions.conf_int()\n",
    "ax = benchmark_pred_df.plot(label = \"benchmark\", figsize=(15, 7))\n",
    "predictions.predicted_mean.plot(ax = ax,alpha = 1)\n",
    "ax.fill_between(prediction_ci.index, \n",
    "                prediction_ci.iloc[:, 0], \n",
    "                prediction_ci.iloc[:, 1], \n",
    "                color = \"k\", alpha = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e24e1-bf77-4de5-a6bc-12c7e9bf8dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the benchmark data in the format for the forecast, specific to prophet package\n",
    "\n",
    "benchmark_pred_ts = benchmark_pred_df\n",
    "benchmark_pred_ts.columns = [\"ds\",\"y\", \"observed\"]\n",
    "benchmark_pred_ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ac4e1-ca37-4d65-9830-9f2e4524ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages for forecasting a year point forward based on the results of the boosting model\n",
    "from prophet import Prophet\n",
    "\n",
    "forecast = Prophet()\n",
    "forecast_pred = forecast.fit(benchmark_pred_ts)\n",
    "\n",
    "forecast_results = forecast.make_future_dataframe(periods = 24, freq = \"M\")\n",
    "fore_predictions = forecast.predict(forecast_results)\n",
    "\n",
    "# print the forecasting values as well as upper and lower bounds in comparison\n",
    "fore_predictions[[\"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf59e81-3ecf-4739-a084-63159b43e0b3",
   "metadata": {},
   "source": [
    "\n",
    "3. What is the projected household penetration for the given year? Household penetration is defined as (# Households Involved in Purchase / Total US Households)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c768ec01-77b4-405e-8334-635e48fd163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time box the forecast predictions for a year time period\n",
    "\n",
    "spend_predict = pd.DataFrame(fore_predictions[[\"ds\", \"yhat\"]])\n",
    "spend_predict = spend_predict[(spend_predict[\"ds\"] > \"2021-08-01\") & (spend_predict[\"ds\"] < \"2022-10-01\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f061e9a-ec57-41e4-b3da-e368c28923d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the yearly sum of sales based on the predictions\n",
    "\n",
    "predicted_sum = int(spend_predict['yhat'].sum())\n",
    "predicted_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0fc49e-e727-45d7-9b84-52e008b955f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approximate the averge proportion of sales in comparison to the benchmark using the individual user sales proportions\n",
    "# in comparison to the total monthly sales\n",
    "\n",
    "avg_prop = ((prop_table['sales_proportion']/prop_table['coverage_rate']) / prop_table['benchmark']).mean()\n",
    "avg_prop\n",
    "us_households = 151310000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9e88b-c790-4127-b509-0f88ffe0a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the percent estimate of household penetration\n",
    "\n",
    "household_penetration = ((predicted_sum * avg_prop) / us_households) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a819bbe-fac9-41ba-9066-4bb221dbb6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the metrics used to estimate household penetration, estimate how the individual receipt collection\n",
    "# of the recorded sales is reflected as a proportion of the benchmark to understand the reciept penetration.\n",
    "\n",
    "pred_merge.groupby(['yearmon'])['sales_proportion'].count().sort_values()\n",
    "\n",
    "prop_table = sum_sales.merge(pred_merge.groupby(['yearmon'])['sales_proportion'].count().sort_values(), on = \"yearmon\")\n",
    "prop_table\n",
    "\n",
    "recepit_penetration = (prop_table['sales_proportion']/prop_table['coverage_rate']) / prop_table['benchmark'] * 100\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
